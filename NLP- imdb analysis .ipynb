{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid=SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "df=pd.read_csv('C:\\\\Users\\\\ACER\\\\Desktop\\\\CODEQUEST-ML\\\\IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping NaN values and empty strings \n",
    "\n",
    "df.dropna(inplace=True) #dropping empty values\n",
    "\n",
    "blanks=[]      #starting with an empty list to which empty strings are appended and dropped \n",
    "\n",
    "for i,rv,sn in df.itertuples():\n",
    "    if(rv)==str:\n",
    "        if rv.isspace():\n",
    "            blanks.append(i)\n",
    "            \n",
    "df.drop(blanks,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()  #this shows that there are no empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEXT CLEANING TECHNIQUES\n",
    "\n",
    "\n",
    "# REMOVING HTML CONTENT \n",
    "\n",
    "\n",
    "\n",
    "rev=df.loc[0]['review']\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(rev, \"html.parser\")\n",
    "rev = soup.get_text()\n",
    "rev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "polarity_scores() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-a3d06918b3a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mrev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: polarity_scores() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "#REMOVING PUNCTUATIONS \n",
    "\n",
    "import re\n",
    "\n",
    "rev = re.sub('\\[[^]]*\\]', ' ', rev)  #used to replace those symbols with space \n",
    "#rev = re.sub('[^a-zA-Z]', ' ', rev)\n",
    "rev\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAKING EVERYTHING LOWER CASE \n",
    "rev=rev.lower()\n",
    "rev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " \"you'll\",\n",
       " 'be',\n",
       " 'hooked.',\n",
       " 'they',\n",
       " 'are',\n",
       " 'right,',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'me.the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'about',\n",
       " 'oz',\n",
       " 'was',\n",
       " 'its',\n",
       " 'brutality',\n",
       " 'and',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'violence,',\n",
       " 'which',\n",
       " 'set',\n",
       " 'in',\n",
       " 'right',\n",
       " 'from',\n",
       " 'the',\n",
       " 'word',\n",
       " 'go.',\n",
       " 'trust',\n",
       " 'me,',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'show',\n",
       " 'for',\n",
       " 'the',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'or',\n",
       " 'timid.',\n",
       " 'this',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'no',\n",
       " 'punches',\n",
       " 'with',\n",
       " 'regards',\n",
       " 'to',\n",
       " 'drugs,',\n",
       " 'sex',\n",
       " 'or',\n",
       " 'violence.',\n",
       " 'its',\n",
       " 'is',\n",
       " 'hardcore,',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word.it',\n",
       " 'is',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'as',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary.',\n",
       " 'it',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'emerald',\n",
       " 'city,',\n",
       " 'an',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'have',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'and',\n",
       " 'face',\n",
       " 'inwards,',\n",
       " 'so',\n",
       " 'privacy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda.',\n",
       " 'em',\n",
       " 'city',\n",
       " 'is',\n",
       " 'home',\n",
       " 'to',\n",
       " 'many..aryans,',\n",
       " 'muslims,',\n",
       " 'gangstas,',\n",
       " 'latinos,',\n",
       " 'christians,',\n",
       " 'italians,',\n",
       " 'irish',\n",
       " 'and',\n",
       " 'more....so',\n",
       " 'scuffles,',\n",
       " 'death',\n",
       " 'stares,',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'and',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'are',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'the',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'of',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'where',\n",
       " 'other',\n",
       " 'shows',\n",
       " \"wouldn't\",\n",
       " 'dare.',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'for',\n",
       " 'mainstream',\n",
       " 'audiences,',\n",
       " 'forget',\n",
       " 'charm,',\n",
       " 'forget',\n",
       " 'romance...oz',\n",
       " \"doesn't\",\n",
       " 'mess',\n",
       " 'around.',\n",
       " 'the',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'i',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'as',\n",
       " 'so',\n",
       " 'nasty',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surreal,',\n",
       " 'i',\n",
       " \"couldn't\",\n",
       " 'say',\n",
       " 'i',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'it,',\n",
       " 'but',\n",
       " 'as',\n",
       " 'i',\n",
       " 'watched',\n",
       " 'more,',\n",
       " 'i',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'taste',\n",
       " 'for',\n",
       " 'oz,',\n",
       " 'and',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'graphic',\n",
       " 'violence.',\n",
       " 'not',\n",
       " 'just',\n",
       " 'violence,',\n",
       " 'but',\n",
       " 'injustice',\n",
       " '(crooked',\n",
       " 'guards',\n",
       " \"who'll\",\n",
       " 'be',\n",
       " 'sold',\n",
       " 'out',\n",
       " 'for',\n",
       " 'a',\n",
       " 'nickel,',\n",
       " 'inmates',\n",
       " \"who'll\",\n",
       " 'kill',\n",
       " 'on',\n",
       " 'order',\n",
       " 'and',\n",
       " 'get',\n",
       " 'away',\n",
       " 'with',\n",
       " 'it,',\n",
       " 'well',\n",
       " 'mannered,',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'being',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'or',\n",
       " 'prison',\n",
       " 'experience)',\n",
       " 'watching',\n",
       " 'oz,',\n",
       " 'you',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'what',\n",
       " 'is',\n",
       " 'uncomfortable',\n",
       " 'viewing....thats',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'darker',\n",
       " 'side.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the text to remove the STOPWORDS from \n",
    "\n",
    "\n",
    "rev = rev.split()\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewers',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'hooked.',\n",
       " 'right,',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'me.the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'violence,',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go.',\n",
       " 'trust',\n",
       " 'me,',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'timid.',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'punches',\n",
       " 'regards',\n",
       " 'drugs,',\n",
       " 'sex',\n",
       " 'violence.',\n",
       " 'hardcore,',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word.it',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary.',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'emerald',\n",
       " 'city,',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cells',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'face',\n",
       " 'inwards,',\n",
       " 'privacy',\n",
       " 'high',\n",
       " 'agenda.',\n",
       " 'em',\n",
       " 'city',\n",
       " 'home',\n",
       " 'many..aryans,',\n",
       " 'muslims,',\n",
       " 'gangstas,',\n",
       " 'latinos,',\n",
       " 'christians,',\n",
       " 'italians,',\n",
       " 'irish',\n",
       " 'more....so',\n",
       " 'scuffles,',\n",
       " 'death',\n",
       " 'stares,',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'goes',\n",
       " 'shows',\n",
       " 'dare.',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'mainstream',\n",
       " 'audiences,',\n",
       " 'forget',\n",
       " 'charm,',\n",
       " 'forget',\n",
       " 'romance...oz',\n",
       " 'mess',\n",
       " 'around.',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasty',\n",
       " 'surreal,',\n",
       " 'say',\n",
       " 'ready',\n",
       " 'it,',\n",
       " 'watched',\n",
       " 'more,',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'oz,',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'graphic',\n",
       " 'violence.',\n",
       " 'violence,',\n",
       " 'injustice',\n",
       " '(crooked',\n",
       " 'guards',\n",
       " \"who'll\",\n",
       " 'sold',\n",
       " 'nickel,',\n",
       " 'inmates',\n",
       " \"who'll\",\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'it,',\n",
       " 'well',\n",
       " 'mannered,',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'turned',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'prison',\n",
       " 'experience)',\n",
       " 'watching',\n",
       " 'oz,',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'uncomfortable',\n",
       " 'viewing....thats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVING STOPWORDS\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "rev = [word for word in rev if not word in set(stopwords.words('english'))]\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewer',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'hooked.',\n",
       " 'right,',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'me.the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scene',\n",
       " 'violence,',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go.',\n",
       " 'trust',\n",
       " 'me,',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'timid.',\n",
       " 'show',\n",
       " 'pull',\n",
       " 'punch',\n",
       " 'regard',\n",
       " 'drugs,',\n",
       " 'sex',\n",
       " 'violence.',\n",
       " 'hardcore,',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word.it',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary.',\n",
       " 'focus',\n",
       " 'mainly',\n",
       " 'emerald',\n",
       " 'city,',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cell',\n",
       " 'glass',\n",
       " 'front',\n",
       " 'face',\n",
       " 'inwards,',\n",
       " 'privacy',\n",
       " 'high',\n",
       " 'agenda.',\n",
       " 'em',\n",
       " 'city',\n",
       " 'home',\n",
       " 'many..aryans,',\n",
       " 'muslims,',\n",
       " 'gangstas,',\n",
       " 'latinos,',\n",
       " 'christians,',\n",
       " 'italians,',\n",
       " 'irish',\n",
       " 'more....so',\n",
       " 'scuffles,',\n",
       " 'death',\n",
       " 'stares,',\n",
       " 'dodgy',\n",
       " 'dealing',\n",
       " 'shady',\n",
       " 'agreement',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'go',\n",
       " 'show',\n",
       " 'dare.',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'picture',\n",
       " 'painted',\n",
       " 'mainstream',\n",
       " 'audiences,',\n",
       " 'forget',\n",
       " 'charm,',\n",
       " 'forget',\n",
       " 'romance...oz',\n",
       " 'mess',\n",
       " 'around.',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasty',\n",
       " 'surreal,',\n",
       " 'say',\n",
       " 'ready',\n",
       " 'it,',\n",
       " 'watched',\n",
       " 'more,',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'oz,',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'high',\n",
       " 'level',\n",
       " 'graphic',\n",
       " 'violence.',\n",
       " 'violence,',\n",
       " 'injustice',\n",
       " '(crooked',\n",
       " 'guard',\n",
       " \"who'll\",\n",
       " 'sold',\n",
       " 'nickel,',\n",
       " 'inmate',\n",
       " \"who'll\",\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'it,',\n",
       " 'well',\n",
       " 'mannered,',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmate',\n",
       " 'turned',\n",
       " 'prison',\n",
       " 'bitch',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skill',\n",
       " 'prison',\n",
       " 'experience)',\n",
       " 'watching',\n",
       " 'oz,',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'uncomfortable',\n",
       " 'viewing....thats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WE DO LEMMETIZATION OF THE WORDS \n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "rev = [lem.lemmatize(word) for word in rev]\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one reviewer mentioned watching 1 oz episode hooked. right, exactly happened me.the first thing struck oz brutality unflinching scene violence, set right word go. trust me, show faint hearted timid. show pull punch regard drugs, sex violence. hardcore, classic use word.it called oz nickname given oswald maximum security state penitentary. focus mainly emerald city, experimental section prison cell glass front face inwards, privacy high agenda. em city home many..aryans, muslims, gangstas, latinos, christians, italians, irish more....so scuffles, death stares, dodgy dealing shady agreement never far away.i would say main appeal show due fact go show dare. forget pretty picture painted mainstream audiences, forget charm, forget romance...oz mess around. first episode ever saw struck nasty surreal, say ready it, watched more, developed taste oz, got accustomed high level graphic violence. violence, injustice (crooked guard who'll sold nickel, inmate who'll kill order get away it, well mannered, middle class inmate turned prison bitch due lack street skill prison experience) watching oz, may become comfortable uncomfortable viewing....thats get touch darker side.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the words to form cleaned up version of the text ----- JOINING THE WORDS\n",
    "\n",
    "rev = ' '.join(rev)\n",
    "rev\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our next step will be to bring this text in \"mathematical forms\" and to do so we will create a ~ Corpus ~ first.\n",
    "\n",
    "corpus = []\n",
    "corpus.append(rev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.11888766, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.11888766, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.11888766, 0.05944383, 0.05944383,\n",
       "        0.11888766, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.11888766,\n",
       "        0.05944383, 0.17833149, 0.05944383, 0.05944383, 0.11888766,\n",
       "        0.05944383, 0.05944383, 0.11888766, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.11888766,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.11888766, 0.05944383,\n",
       "        0.05944383, 0.17833149, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.11888766, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.11888766, 0.05944383, 0.05944383, 0.05944383, 0.11888766,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.35666298, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.17833149, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.11888766, 0.05944383, 0.05944383, 0.11888766, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.23777532, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.11888766,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.05944383, 0.05944383,\n",
       "        0.05944383, 0.05944383, 0.05944383, 0.23777532, 0.05944383,\n",
       "        0.11888766, 0.05944383, 0.11888766, 0.11888766, 0.05944383]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO VECTORIZE THE WORDS WE USE TFID-VECTORIZER \n",
    "\n",
    "# this will return an array with frequency in which the word appears \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "review_tfidf_vec = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "review_tfidf_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE ARE GOING TO SPLIT THE TRAIN AND THE TEST DATASETS with 25% of test data ad remaining as train data\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_train, dataset_test, train_data_label, test_data_label = train_test_split(df['review'], df['sentiment'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the sentiments to NUMERIC form\n",
    "\n",
    "\n",
    "train_data_label = (train_data_label.replace({'positive': 1, 'negative': 0})).values\n",
    "test_data_label  = (test_data_label.replace({'positive': 1, 'negative': 0})).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOING TO APPLY THE ABOVE PREPROCESSING OF DATA FOR ALL THE REVIEWS \n",
    "\n",
    "\n",
    "\n",
    "corpus_train = []\n",
    "corpus_test  = []\n",
    "\n",
    "\n",
    "#DOING FOR TRAIN DATA SET (REVIEWS)\n",
    "\n",
    "for i in range(dataset_train.shape[0]):\n",
    "    soup = BeautifulSoup(dataset_train.iloc[i], \"html.parser\")\n",
    "    review = soup.get_text()\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    lem = WordNetLemmatizer()\n",
    "    review = [lem.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    corpus_train.append(review)\n",
    "    \n",
    "#DOING FOR TEST DATA SET (REVIEWS)\n",
    "    \n",
    "for j in range(dataset_test.shape[0]):\n",
    "    soup = BeautifulSoup(dataset_test.iloc[j], \"html.parser\")\n",
    "    review = soup.get_text()\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    lem = WordNetLemmatizer()\n",
    "    review = [lem.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDATING A CASE\n",
    "\n",
    "\n",
    "\n",
    "corpus_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
